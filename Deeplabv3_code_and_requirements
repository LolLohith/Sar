Great! You're asking for a **Python semantic segmentation training script** that:

* Uses **manually labeled masks** from the `Cleaned_Edges/` folder as ground truth labels.
* Uses **Gabor-filtered images** from the `Gabor_Labelled/` folder as input images **without modification**.
* Trains a **DeepLabV3+** model (or equivalent).

---

### ‚úÖ Summary of Requirements:

| Input folder      | Purpose                       |
| ----------------- | ----------------------------- |
| `Gabor_Labelled/` | Input images (Gabor filtered) |
| `Cleaned_Edges/`  | Manually labeled masks        |

---

## ‚úÖ Python Code: Train DeepLabv3+ with Gabor & Manual Edge Labels

### Step 1: Folder Structure

```
dataset/
‚îú‚îÄ‚îÄ Gabor_Labelled/
‚îÇ   ‚îú‚îÄ‚îÄ image1.png
‚îÇ   ‚îú‚îÄ‚îÄ image2.png
‚îú‚îÄ‚îÄ Cleaned_Edges/
‚îÇ   ‚îú‚îÄ‚îÄ image1.png
‚îÇ   ‚îú‚îÄ‚îÄ image2.png
```

Ensure that **file names match exactly** between images and masks.

---

### Step 2: Install Dependencies

Install required libraries:

```bash
pip install torch torchvision segmentation-models-pytorch albumentations opencv-python
```

---

### Step 3: Full Training Script

```python
import os
import cv2
import numpy as np
from glob import glob
from tqdm import tqdm
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2

# Set paths
IMAGE_DIR = 'dataset/Gabor_Labelled'
MASK_DIR = 'dataset/Cleaned_Edges'

# Dataset
class SegDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None):
        self.image_paths = sorted(glob(os.path.join(image_dir, '*.png')))
        self.mask_paths = sorted(glob(os.path.join(mask_dir, '*.png')))
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = cv2.imread(self.image_paths[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(self.mask_paths[idx], 0)
        mask = (mask > 0).astype('float32')  # Binary

        if self.transform:
            aug = self.transform(image=img, mask=mask)
            img = aug['image']
            mask = aug['mask'].unsqueeze(0)  # (1, H, W)

        return img, mask

# Transforms
transform = A.Compose([
    A.Resize(512, 512),
    A.Normalize(),
    ToTensorV2()
])

# Dataloaders
train_ds = SegDataset(IMAGE_DIR, MASK_DIR, transform=transform)
train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)

# Model
model = smp.DeepLabV3Plus(encoder_name="resnet18", in_channels=3, classes=1, activation=None)
model = model.cuda()

# Training setup
loss_fn = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Training loop
for epoch in range(20):
    model.train()
    total_loss = 0

    for imgs, masks in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
        imgs = imgs.cuda()
        masks = masks.cuda()

        preds = model(imgs)
        loss = loss_fn(preds, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch {epoch+1} Loss: {total_loss:.4f}")

# Save model
torch.save(model.state_dict(), 'deeplabv3plus_gabor.pth')
print("Training complete and model saved.")
```

---

### ‚úÖ Output

* Trained DeepLabV3+ model: `deeplabv3plus_gabor.pth`
* Uses:

  * Gabor-filtered images as-is
  * Cleaned edge masks as ground truth (binary segmentation)

---

### ‚úÖ Inference Example

To predict on a new Gabor image:

```python
def predict_single_image(model, img_path):
    model.eval()
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    tfm = A.Compose([
        A.Resize(512, 512),
        A.Normalize(),
        ToTensorV2()
    ])
    input_tensor = tfm(image=img)['image'].unsqueeze(0).cuda()

    with torch.no_grad():
        output = model(input_tensor)
        mask = torch.sigmoid(output).squeeze().cpu().numpy()
        return (mask > 0.5).astype(np.uint8)

# Example
mask = predict_single_image(model, 'dataset/Gabor_Labelled/image1.png')
cv2.imwrite('predicted_mask.png', mask * 255)
```

---

## üîÅ Optional Extensions

* For **multiclass classification**, replace:

  * `classes=1 ‚Üí classes=6`
  * `BCEWithLogitsLoss ‚Üí CrossEntropyLoss`
  * Mask format: integer values (0‚Äì5)

Let me know if you'd like the **multiclass version**, or help setting up the **label mapping and color decoding**.

Would you like:

* Evaluation (IoU, Dice)?
* Real-time visualization?
* CRF or edge-enhanced predictions?

I can extend the script accordingly.
