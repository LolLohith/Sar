Great! You're asking for a **Python semantic segmentation training script** that:

* Uses **manually labeled masks** from the `Cleaned_Edges/` folder as ground truth labels.
* Uses **Gabor-filtered images** from the `Gabor_Labelled/` folder as input images **without modification**.
* Trains a **DeepLabV3+** model (or equivalent).

---

### ✅ Summary of Requirements:

| Input folder      | Purpose                       |
| ----------------- | ----------------------------- |
| `Gabor_Labelled/` | Input images (Gabor filtered) |
| `Cleaned_Edges/`  | Manually labeled masks        |

---

## ✅ Python Code: Train DeepLabv3+ with Gabor & Manual Edge Labels

### Step 1: Folder Structure

```
dataset/
├── Gabor_Labelled/
│   ├── image1.png
│   ├── image2.png
├── Cleaned_Edges/
│   ├── image1.png
│   ├── image2.png
```

Ensure that **file names match exactly** between images and masks.

---

### Step 2: Install Dependencies

Install required libraries:

```bash
pip install torch torchvision segmentation-models-pytorch albumentations opencv-python
```

---

### Step 3: Full Training Script

```python
import os
import cv2
import numpy as np
from glob import glob
from tqdm import tqdm
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2

# Set paths
IMAGE_DIR = 'dataset/Gabor_Labelled'
MASK_DIR = 'dataset/Cleaned_Edges'

# Dataset
class SegDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None):
        self.image_paths = sorted(glob(os.path.join(image_dir, '*.png')))
        self.mask_paths = sorted(glob(os.path.join(mask_dir, '*.png')))
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = cv2.imread(self.image_paths[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(self.mask_paths[idx], 0)
        mask = (mask > 0).astype('float32')  # Binary

        if self.transform:
            aug = self.transform(image=img, mask=mask)
            img = aug['image']
            mask = aug['mask'].unsqueeze(0)  # (1, H, W)

        return img, mask

# Transforms
transform = A.Compose([
    A.Resize(512, 512),
    A.Normalize(),
    ToTensorV2()
])

# Dataloaders
train_ds = SegDataset(IMAGE_DIR, MASK_DIR, transform=transform)
train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=2)

# Model
model = smp.DeepLabV3Plus(encoder_name="resnet18", in_channels=3, classes=1, activation=None)
model = model.cuda()

# Training setup
loss_fn = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Training loop
for epoch in range(20):
    model.train()
    total_loss = 0

    for imgs, masks in tqdm(train_loader, desc=f"Epoch {epoch+1}"):
        imgs = imgs.cuda()
        masks = masks.cuda()

        preds = model(imgs)
        loss = loss_fn(preds, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    print(f"Epoch {epoch+1} Loss: {total_loss:.4f}")

# Save model
torch.save(model.state_dict(), 'deeplabv3plus_gabor.pth')
print("Training complete and model saved.")
```

---

### ✅ Output

* Trained DeepLabV3+ model: `deeplabv3plus_gabor.pth`
* Uses:

  * Gabor-filtered images as-is
  * Cleaned edge masks as ground truth (binary segmentation)

---

### ✅ Inference Example

To predict on a new Gabor image:

```python
def predict_single_image(model, img_path):
    model.eval()
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    tfm = A.Compose([
        A.Resize(512, 512),
        A.Normalize(),
        ToTensorV2()
    ])
    input_tensor = tfm(image=img)['image'].unsqueeze(0).cuda()

    with torch.no_grad():
        output = model(input_tensor)
        mask = torch.sigmoid(output).squeeze().cpu().numpy()
        return (mask > 0.5).astype(np.uint8)

# Example
mask = predict_single_image(model, 'dataset/Gabor_Labelled/image1.png')
cv2.imwrite('predicted_mask.png', mask * 255)
```

---

## 🔁 Optional Extensions

* For **multiclass classification**, replace:

  * `classes=1 → classes=6`
  * `BCEWithLogitsLoss → CrossEntropyLoss`
  * Mask format: integer values (0–5)

Let me know if you'd like the **multiclass version**, or help setting up the **label mapping and color decoding**.

Would you like:

* Evaluation (IoU, Dice)?
* Real-time visualization?
* CRF or edge-enhanced predictions?

I can extend the script accordingly.





Absolutely! Here's how you can implement the same segmentation task using **TensorFlow / Keras** instead of PyTorch, based on your structure:

---

## ✅ Objective Recap

* Input: **Gabor-filtered images** from `Gabor_Labelled/`
* Labels: **Manual edge masks** from `Cleaned_Edges/`
* Task: Train a **DeepLabV3+**-like model to predict area segmentation.

---

## ✅ Requirements

First, install necessary packages:

```bash
pip install tensorflow opencv-python numpy albumentations
```

---

## ✅ Step-by-Step TensorFlow Implementation

### 🔧 Step 1: Folder Structure

```
dataset/
├── Gabor_Labelled/
│   ├── image1.png
│   ├── image2.png
├── Cleaned_Edges/
│   ├── image1.png
│   ├── image2.png
```

---

### 📦 Step 2: Data Loader (TensorFlow Custom Generator)

```python
import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import Sequence
from sklearn.model_selection import train_test_split
import albumentations as A

class SegDataGenerator(Sequence):
    def __init__(self, img_paths, mask_paths, batch_size=8, augment=False):
        self.img_paths = img_paths
        self.mask_paths = mask_paths
        self.batch_size = batch_size
        self.augment = augment
        self.transform = A.Compose([
            A.Resize(512, 512),
            A.Normalize(),
        ])
        
    def __len__(self):
        return int(np.ceil(len(self.img_paths) / self.batch_size))

    def __getitem__(self, idx):
        batch_img_paths = self.img_paths[idx * self.batch_size:(idx + 1) * self.batch_size]
        batch_mask_paths = self.mask_paths[idx * self.batch_size:(idx + 1) * self.batch_size]

        imgs, masks = [], []

        for img_path, mask_path in zip(batch_img_paths, batch_mask_paths):
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            mask = cv2.imread(mask_path, 0)  # grayscale

            mask = (mask > 0).astype('float32')  # binary mask

            augmented = self.transform(image=img, mask=mask)
            img = augmented['image']
            mask = augmented['mask']

            imgs.append(img)
            masks.append(mask[..., np.newaxis])

        return np.array(imgs), np.array(masks)
```

---

### 🧠 Step 3: DeepLabV3+ Model (Keras)

Use **TensorFlow's official DeepLabV3+** from `tensorflow_models` or a custom approximation.

✅ For simplicity, here's a **U-Net alternative**, since TensorFlow doesn’t include DeepLabV3+ by default:

```python
def simple_unet(input_shape=(512, 512, 3)):
    inputs = tf.keras.Input(input_shape)
    
    c1 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)
    c1 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c1)
    p1 = tf.keras.layers.MaxPooling2D()(c1)

    c2 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(p1)
    c2 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c2)
    p2 = tf.keras.layers.MaxPooling2D()(c2)

    c3 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p2)
    c3 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c3)

    u1 = tf.keras.layers.UpSampling2D()(c3)
    u1 = tf.keras.layers.Concatenate()([u1, c2])
    c4 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(u1)
    c4 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c4)

    u2 = tf.keras.layers.UpSampling2D()(c4)
    u2 = tf.keras.layers.Concatenate()([u2, c1])
    c5 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(u2)
    c5 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c5)

    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c5)

    model = tf.keras.Model(inputs, outputs)
    return model
```

---

### 🚀 Step 4: Train the Model

```python
# Get file paths
image_paths = sorted([os.path.join('dataset/Gabor_Labelled', f) for f in os.listdir('dataset/Gabor_Labelled')])
mask_paths = sorted([os.path.join('dataset/Cleaned_Edges', f) for f in os.listdir('dataset/Cleaned_Edges')])

# Split dataset
train_imgs, val_imgs, train_masks, val_masks = train_test_split(image_paths, mask_paths, test_size=0.2, random_state=42)

# Generators
train_gen = SegDataGenerator(train_imgs, train_masks, batch_size=4)
val_gen = SegDataGenerator(val_imgs, val_masks, batch_size=4)

# Build and compile model
model = simple_unet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train
model.fit(train_gen, validation_data=val_gen, epochs=20)

# Save
model.save('gabor_edge_segmentation_model.h5')
```

---

### 🔍 Step 5: Predict on New Gabor Image

```python
def predict_image(model, img_path):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = A.Resize(512, 512)(image=img)['image']
    img = A.Normalize()(image=img)['image']
    img = np.expand_dims(img, 0)

    pred = model.predict(img)[0, :, :, 0]
    return (pred > 0.5).astype(np.uint8)

# Example usage
mask = predict_image(model, 'dataset/Gabor_Labelled/image1.png')
cv2.imwrite('predicted_mask.png', mask * 255)
```

---

## ✅ Summary

| Component | Description                                       |
| --------- | ------------------------------------------------- |
| Framework | TensorFlow / Keras                                |
| Input     | Gabor-filtered RGB image                          |
| Label     | Binary mask from manual edge-cleaned labels       |
| Model     | U-Net (or replace with DeepLabV3+ from TF Models) |
| Output    | Predicted binary area segmentation                |

---

## 🚀 Optional Upgrades

* Switch to **multiclass segmentation** (`categorical_crossentropy`).
* Use **TensorFlow Model Garden** for actual **DeepLabV3+**:
  [https://github.com/tensorflow/models/tree/master/research/deeplab](https://github.com/tensorflow/models/tree/master/research/deeplab)
* Add **boundary-aware loss** or edge-channel input.

Would you like a version using **true DeepLabV3+** from the TensorFlow Model Zoo (with pretrained backbones like Xception or MobileNet)?
